# Data Analytics Fundamentals
https://www.aws.training/Details/eLearning?id=35364

## レッスン1: データ分析ソリューションの紹介
レッスンで扱うトピック
* データ分析とデータ分析ソリューション
* データ分析に関する課題の紹介

### トピック1: データ分析とデータ分析ソリューション
主要なコンポーネント
* 収集 (gathering)
* 保存 (store)
* 処理 (processing)
* 分析 (analyze)

### トピック2: データ分析の課題の紹介

#### 5V
![5V](5v.png "5V")

* Volume (ボリューム)
  * ソリューションが処理しなければならないデータの量
* Velocity (速度)
  * ソリューションにデータが入り通過していく速度
* Variety (多様性)
  * ソリューションが扱えるデータの種類
  * 構造化データ、半構造化データ、非構造化データ
* Volality (信憑性)
  * 信頼性、データのProvenanceを知る
  * Provenance: データの生成から現在までの過程を知ること
* Value (価値)
  * 最も肝心なことはデータから価値を引き出すこと

#### データ分析ソリューションを計画する
* データの取得元
  * オンプレミスのデータベース・ファイルストア
  * ストリーミングデータ
    * リアルタイムで正確に集計して分析するには、特別なソフトウェア・アプリケーションが必要になる場合も
  * パブリックデータセット
    * ビジネスに必要な情報のみが含まれるように、変換が必要になる場合も
* データを処理するためのオプションを知る
* データから何を学ぶかを知る

## レッスン2: ボリューム - データストレージ
レッスンで扱うトピック
* Amazon Simple Storage Service (Amazon S3) の紹介
* データレイクの紹介
* データストレージメソッドの紹介

### ビジネスデータの急激な増加
* 企業がその処理および分析能力を超えたデータを抱えると、ボリュームの問題が発生する
* 企業におけるデータの構造化、半構造化、非構造化の比率は 80:10:10 との研究も

### トピック1: Amazon S3の紹介
Amazon S3: 任意の量のデータの保存と取得をどこからでも行えるように設計されたオブジェクトストレージです
* オブジェクト: ファイルおよび任意のメタデータで構成
* バケット: オブジェクトの「入れ物」
  * アカウントに1つ以上のバケットを配置でき、バケットごとにアクセスを制御可能
  * バケットのオブジェクトを作成、削除、一覧表示できるユーザーを指定可能
* オブジェクトの識別子
  * `s3://{bucket}.s3.amazonaws.com/{prefix}/{object}`
  * `{prefix} + {object}` = object key
* S3の利点
  * ストレージをコンピューティング・データ処理から疎結合化
  * 一元化されたデータアーキテクチャ
  * クラスターレス
  * サーバレスなAWSサービスとの結合
  * 標準化されたAPI

### トピック2: データレイクの概要
![データレイク](datalake.png "データレイク")

* データレイク: 規模にかかわらず、構造化データ、半構造化データ、非構造化データを保存できる一元管理リポジトリ
* AWSはS3でこれを実現
* データレイクの利点
  1. ほぼ無制限の量のデータを永続的に保存
  2. セキュリティとコンプライアンス
  3. 様々なデータ収集ツールや取り込みツールを利用可能 (ex. Kinesis)
  4. データを簡単かつ効率的に分類・管理 (ex. Glue)
  5. データを意味のある情報に変換 (ex. EMR)

#### データレイクの準備
```
データサイエンティストは、時間の 60％をデータのクリーンアップと
整理に費やし、19％ をデータセットの収集に費やしています。
```

* AWSのデータレイクは、次の作業に役立つ
  * データの形式や規模を問わず、低コストで収集し保存する
  * データを保護し、不正アクセスを防ぐ
  * 中央リポジトリでデータを管理し、カタログ作成、検索、有用なデータの特定を行う
  * 新しいタイプのデータ分析をすばやく簡単に実行する
 * ワンタイム分析、リアルタイムストリーミング、予測分析、AI、機械学習を扱う幅広い分析エンジンを利用する
* AWS Lake Formation (現在はプレビュー版のみ利用可)
  * データの整理とキュレーション
    * データの取り込み、消去、カタログ化、変換、保護が簡単に
  * データレイク全体のデータを保護
  * 変換ジョブを他のAWSサービスと調整
  * 安全なデータレイクを数日で簡単にセットアップ可能

### トピック3: データストレージ方法の概要
#### データウェアハウス
![データウェアハウス](datawarehouse.png "データウェアハウス")

* 1つ以上のデータソースからもたらされる情報の中央リポジトリ
* データは、トランザクションシステム、リレーショナルデータベース、その他のソースからデータウェアハウスに流れる
* これらのデータソースには、構造化データ、半構造化データ、非構造化データを含めることができるが、データウェアハウスに保存される前に構造化データに変換される
* データを格納する方法はスキーマで定義 (RDBと同じ)
* I/O を最小化するよう効率よくデータを保存、何百・何千というユーザーからのクエリを高速かつ同時に処理

#### データマート
![データウェアマート](datamart.png "データマート")

* データウェアハウスからのデータのサブセットを、データマートと呼ぶ
* データマートは1つの主題または機能領域にのみ焦点を合わせる

#### データウェアハウスとデータレイクの比較

| 特徴 | データウェアハウス | データレイク |
|--|--|--|
| データ | トランザクションシステム、運用データベース、基幹業務アプリケーションからのリレーショナルデータ | IoT デバイス、ウェブサイト、モバイルアプリケーション、ソーシャルメディア、企業アプリケーションからの非リレーショナルおよびリレーショナルデータ |
| スキーマ | データ格納前に設計 (スキーマオンライト) | データ分析時に解釈 (スキーマオンリード)
| 価格/ パフォーマンス | 高コストのストレージを使用してクエリ結果を最速で取得 | 低コストのストレージを使用してクエリ結果をより速く取得 |
| データ品質 | 高度にキュレートされたデータで、確度の高い情報源 | 任意のデータで、キュレートできるかどうかは不明 (例: 未加工データ) |
| ユーザー | ビジネスアナリスト | (キュレートされたデータを使用する) データサイエンティスト、データ開発者、ビジネスアナリスト | 
| 分析 | バッチレポート、BI、可視化 | 機械学習、予測分析、データ検出、プロファイリング |

#### DWHとOLTPデータベースの違い
* データウェアハウス
  * 高度に構造化されたデータセット用のストレージを提供し、
    分析クエリの信頼できる唯一のソースとして機能
* OLTP データベース
  * 新規および頻繁に更新されるデータの構造化ストアとして機能。分析クエリが頻繁に実行されると、パフォーマンスが低下する場合がある

## レッスン3: 速度 - データ処理
レッスンのトピック
* データ処理方法の概要
* バッチデータ処理の概要
* ストリームデータ処理の概要

### 収集と処理
* 収集: 複数のソースから分析のためのデータを集めること
* 処理: データの初期化・整理により意味のある情報の生成・管理すること

### トピック1: データ処理方法の概要
* 処理の要件
  * バッチ処理: データの大規模バースト
    * 計画的
    * 定期的
  * ストリーム処理: データの小規模バースト
    * リアルタイム (数秒〜数十秒)
    * ほぼリアルタイム (〜数分以内)
  * 処理の要件によって利用するサービスも違う

### トピック2: バッチデータ処理の概要
* バッチ処理は、手動介入なしに1〜複数台のマシンで連続したジョブ(プログラム)を実行すること
* 大量のデータを一度にすばやく効率的に処理する必要がある
* 特定の条件(指定された時刻など)が満たされると、処理システムに送信される
* Amazon EMR: Hadoopワークロードを実装するためのマネージドサービス。EMR Notebooksという開発環境もある？

#### バッチ処理型アーキテクチャ
* ベーシックな構成例
  * データソース -> S3 -> Lambda -> EMR -> Redshift
  * Lambda はスケジュール動作
  * EMRでETL処理(集計やロード処理)を実現
  * EMRでのApache SparkにはMLibも含まれるため、機械学習のようなワークロードも実現可能
* Glueを用いた構成例
  * データソース -> S3 -> Lambda -> Glue -> Redshift
  * GlueはEMRとは対象的にフルマネージドなサービス
  * EMRの替わりにETL処理を実行

### トピック3: ストリームデータ処理の概要
* ストリーミングソリューションは一般的に、プロデューサーとコンシューマーにわかれる
* 各プロデューサーは同一のエンドポイントにデータを書き込むことができるため、
  複数のデータストリームを１つのストリームに結合して処理可能
* データのクライアント順序を維持し、データの並列実行が可能に

#### ストリーム処理アーキテクチャ
* 構成例
  * センサーデータ -> 収集レイヤー[Kinesis Data Firehose] -> 処理レイヤー[Kinesis Data Analytics -> Kinesis Data Firehose] -> S3 -> Athena -> Quicksight
  * 処理レイヤーのKinesis Data Analyticsで関連するレコードのデータをフィルタリング。Kinesis Data FirehoseでS3に結果を送信

#### 結合処理アーキテクチャ
Kinesis Data Firehose -> S3に格納されたセンサーデータと、事前にS3に格納されたデバイスの設定データをGlueで結合し、
サービスレイヤーのS3にロードした例

![ストリーム処理アーキテクチャ](stream-process-arch.png)

ストリームデータ処理とバッチデータ処理を結合したEnd to Endのソリューションの例

![結合処理アーキテクチャ](combined-process-arch.png)

> AWSが [ハンズオンのチュートリアル](https://aws.amazon.com/jp/getting-started/hands-on/build-log-analytics-solution/) を用意してくれているので、試してみてもよさそう

## レッスン4: 多様性 - データの構造とタイプ
レッスンで扱うトピック
* ソースデータストレージの概要
* 構造化データストアの概要
* 半構造化データストアと非構造化データストアの概要

### トピック1: ソースデータストレージの概要
* 構造化データ
  * 一般的に、データベース管理システム (DBMS) にテーブル形式で保存
  * データ要素とそれらの相互関係を定義および標準化するリレーショナルデータモデルに基づいて整理
  * テーブル内の各フィールドが何を表すかを説明するテーブルスキーマによって表現
  * 欠点は **柔軟性がないこと**
    * 例えば、顧客の年齢を追跡する要件が追加された場合、この新しいデータを受容するようにスキーマを再設計する必要がある
  * 構造化データアプリケーションには、Amazon RDS、Amazon Aurora、MySQL、MariaDB、PostgreSQL、Microsoft SQL Server、Oracle などがある
* 半構造化データ
  * 一般的に、ファイル内の要素の形式で保存
  * データ要素とそれを定義する属性（プロパティ）に基づいて整理されます
  * データモデルやスキーマには準拠せず、自己記述式の構造を持つと見なされる
  * トレードオフは **分析** 
    * データアナリストが特定のデータセットに存在する属性を予測できない場合、半構造化データの分析が困難になることがある
  * 半構造化データストアの例は、CSV、XML、JSON、Amazon DynamoDB、Amazon Neptune、Amazon ElastiCache などがある
* 非構造化データ
  * 一般的に、ファイルの形式で保存される
  * 事前定義されたデータモデルに準拠せず、事前定義された方法で整理されない* 非構造化データには、テキスト中心のデータ、写真、音声録音、動画などが含まれる
  * 非構造化データには無関係な情報が大量に含まれているため、意味のある分析を行うにはファイルを事前処理する必要がある
  * 非構造化データの例は、E メール、写真、動画、クリックストリームデータ、Amazon S3、Amazon Redshift Spectrum などがある

> * 構造化データは熱々(Hot)で、すぐに分析できる
> * 半構造化データは生ぬるく、すぐに分析できるものもあれば、クレンジングや事前処理が必要なデータもある
> * 非構造化データは凍った(Cold)海。必要なもので満ち溢れている一方、あらゆる種類の不要なもので分断されている

### トピック2: 構造化データストアの概要
* フラットファイルデータ: ワークシートやスプレッドシートのように表形式で表現されるデータのこと。スキーマによるチェックがなく厳密には構造化されない
* リレーショナルデータベース: テーブルおよびテーブル間の関係性を明確かつ厳格に管理可能なシステムのこと

#### 情報システムの種類
* OLTPデータベース (運用データベース)
  * OLTP=オンライントランザクション処理
  * 主にデータ入力の速度に重点をおいてデータを論理的に整理
  * これらのデータベースはInsert,Update,Deleteが多いという特徴がある
* OLAPデータベース (データウェアハウス)
  * OLAP=オンライン分析処理
  * 主にクエリによるデータ取得の速度に重点をおいてデータを論理的に整理
  * 書き込みオペレーションが比較的少なく、UpdateおよびDeleteがないという特徴がある

| 特徴 | OLTP | OLAP |
|--|--|--|
| 性質 | 間断ないトランザクション | 定期的で大規模な更新、複雑なクエリ |
| 例 | 経理DB、小売トランザクション | レポート、意思決定支援 |
| タイプ | 運用データ | 統合データ |
| データ保持 | 短期(2〜6カ月) |  長期(2〜5年) |
| ストレージサイズ | GB | TB/PB |
| ユーザー | 多数 | 少数 |
| 保護 | 堅牢で一貫性のあるデータ保護と対障害性 | 定期的な保護 |

#### 行指向/列指向データベース
* 行指向データベース
  * 行ベースにインデックスを作成
  * 行指向のOLTP/OLAPシステムをAmazon RDSで構築可能
* 列指向データベース
  * 列ベースにインデックスを作成
  * 列指向のOLAPシステムをAmazon Redshiftで構築可能

| | 行ベースインデックス | 列ベースインデックス |
|--|--|--|
| ディスク上のストレージ | 行単位 | 列単位 |
| 読み取り/書き込み | ランダムな読み書きに最適 | シーケンシャルな読み書きに最適 |
| 最適な用途 | キーに基づいてすべてのデータ行を返す | 列値の集計データを返す |
| 実装 | トランザクションシステム | 分析処理 |
| データ圧縮 | 低〜中程度の圧縮 | 一般的に高圧縮 |

#### ケーススタディ
1. オンプレミスなDBをクラウドに以降する場合に適切なオプションを決定することが大きな課題
    * Amazon RDSを使用
2. 分析リクエストにより、トランザクションシステムがすぐに過負荷になる
    * Amazon Redshiftを使用
    * 自身のDWH内のデータやS3に保存されたデータに対してクエリを実行
      * Amazon Redshift Spectrum : S3データに対して直接クエリを実行可能
      * https://dev.classmethod.jp/articles/amazon-redshift-getting-started-with-spectrum/

### トピック3: 半構造化および非構造化データストアの概要
#### 非リレーショナルデータベース
* 非リレーショナルデータベースは、半構造化データと非構造化データを迅速に収集と取得ができる形で、保存するように作られている
* NoSQLも非リレーショナルデータベースに含まれるとする
* ドキュメントストア
  * JSONやXMLの総称。一連のエレメントが保存されたデータに含まれる
  * 強み
    * 柔軟性、拡張が容易、作成時にデータ構造を計画する必要がない
  * 弱点
    * （データ更新のタイミングによって）[ACID](https://ja.wikipedia.org/wiki/ACID_(%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF%E7%A7%91%E5%AD%A6))コンプライアンスが犠牲になる
    * ファイルをまたいだクエリが不可能
* キーバリューストア
  * Key-Valueのペア形式で非構造化データを保存する非リレーショナルデータベースの一種
  * 強み
    * 非常に柔軟、様々なデータ型を処理できる、インデックス操作・複雑な結合操作を必要としない、キーのコンテンツを他のシステムに容易にコピー可能
  * 弱点
    * 単一のblobとして保存されるため、値をクエリできない
    * 値の内容を更新することが困難
    * すべてのオブジェクトがKey-Valueのペアとして簡単にモデルかされるわけではない (ex.リスト)

#### スキーマの変更
* リレーショナルデータベース
  * 新たな要素を追加する場合
    1. SQLコマンドを実行して列を追加
    2. テーブルに空の列が含まれる
    3. 新しい列に既存の各レコードに値を入力
* 非リレーショナルデータベース
  * 新たな要素を追加する場合
    * その要素をもつレコードを追加するだけ…（各レコードは独自の属性をもてるから）
    * （各レコードの属性が一致していないような状態で、Redshift SpectrumやAthenaって動くのだろうか？）

#### AWSでのオプション
* 非リレーショナルデータベース: DynamoDB, ElastiCache
* グラフデータベース: Naptune

#### 非リレーショナルデータベースの長所と短所
* 利点
  * 動的なスキーマを介してRDBの限界を超えられる
  * その結果、開発サイクルやダウンタイムが短縮される
  * スケーリングに有利で、より大規模なデータセットを処理できる
* 欠点
  * 「結果整合性」：データ変更のタイミングでなくバックグラウンドタスクでこれらの整合性が追いつく
  * 多くの状態では許容されるもの、ACIDコンプライアンスの達成が困難
  * 極めて低いトランザクションレンテンシーが必要とするアプリケーションにおいて、RDBほどパフォーマンスがうまく出せない
  * 成熟度もフィールドの専門知識量もRDBには現時点では到底及ばない

| 特徴 | リレーショナル | 非リレーショナル | グラフ |
|--|--|--|--|
| 表現 | 列と行を含む複数のテーブル | ドキュメントの集合、キーと値を持つ単一のテーブル | ノードとリレーションシップの集合 |
| データ設計 | 正規化されたRDB、またはディメンション（多次元）データウェアハウス | 非正規化エンティティリレーションシップ |
| 最適化 | ストレージに最適 | コンピューティングに最適 | リレーションシップに最適 |
| クエリスタイル | SQL | 言語多数。オブジェクトクエリを使用 | 同左 |
| スケーリング | 垂直スケーリング | 水平スケーリング | ハイブリッド |

## レッスン4: 信憑性 - クレンジングと変換
レッスンで扱うトピック
* データの整合性について理解する
* データベースの一貫性について理解する
* ETLプロセスの紹介

### 用語の定義
* キュレーション: コレクション内のアイテムを選択、整理、整備するアクションまたはプロセス
* データの整合性: データのライフサイクル全体にわたって維持、保証されている正確性と一貫性
* データの信憑性: データの正確性、精度、信頼性の度合いのことです

### 信憑性の問題
* データは時間の経過とともに変化する
* プロセス間やシステム間で転送されているうちに、データの整合性が低下する場合がある。自分が分析しているデータが信頼できるものであるという確実性を、高いレベルに維持する必要がある
